## Chat-GPT-4o prompt engineering
https://platform.openai.com/docs/guides/prompt-engineering

## facts
- CHAT-GPT is part of a dynamic architecture rather than a single static model
- OpenAI doesn't officially disclose the exact parameter count for GPT-4, but itâ€™s known to have significantly more than the 175 billion parameters used in GPT-3.
- It runs with optimizations that may involve multiple models or subsystems working together for better efficiency and performance in various tasks.
- Its architecture adapts to support multimodal inputs and generate complex outputs based on various tools like code execution and web searches.


## MetaAi prompt engineering
https://www.promptingguide.ai/techniques/meta-prompting

## facts
- MetaAi based on LLaMA, a large language model developed by Meta.
- It's running on LLaMA 2, a more advanced version of the LLaMA model.
- It is a 70B parameter model, and it is a single model, not an ensemble. It is based on the LLaMA 2 model architecture.


## Claude
https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview

## facts
- Claude 3.5 Sonnet, part of the Claude 3 model family released by Anthropic in 2024.
- Claude runs on its own proprietary large language model developed by Anthropic. It's not based on OpenAI's GPT architecture but rather a separate system designed with a strong emphasis on ethical AI, safety, and interpretability. 
- Anthropic hasn't publicly confirmed whether Claude operates as a single monolithic model or as a dynamic ensemble system.


## DeepSeek
https://github.com/deepseek-ai/DeepSeek-LLM

## Facts
- DeepSeek-V3, an AI assistant independently developed by the Chinese company DeepSeek Inc.
- Specific architecture or version of the model is proprietary and not publicly disclosed.
